{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 tokenizer and model\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2', device_map='auto')\n",
    "# Add a padding token to GPT-2 tokenizer (since it doesn't have one by default)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset of the IMDb dataset for binary sentiment classification\n",
    "dataset = datasets.load_dataset('imdb', split='train[:25%]')\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ce0815c5da44b68376f2a36b835bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab74e0359634bb3a3d3acb78a531f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply the tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove unnecessary columns and set format for PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['text'])\n",
    "tokenized_datasets.set_format('torch')\n",
    "\n",
    "# Split into train and evaluation datasets\n",
    "train_dataset = tokenized_datasets['train']\n",
    "eval_dataset = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom model with GPT-2 as feature extractor and a linear classifier on top\n",
    "class GPT2ForClassification(torch.nn.Module):\n",
    "    def __init__(self, gpt2, num_labels):\n",
    "        super(GPT2ForClassification, self).__init__()\n",
    "        self.gpt2 = gpt2\n",
    "        # Freeze GPT-2 parameters\n",
    "        for param in self.gpt2.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Linear classifier\n",
    "        self.classifier = torch.nn.Linear(self.gpt2.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # Get hidden states from GPT-2\n",
    "        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use the hidden state of the last token for classification\n",
    "        last_token_indices = attention_mask.sum(dim=1) - 1\n",
    "        pooled_output = outputs.last_hidden_state[torch.arange(input_ids.size(0)), last_token_indices]\n",
    "        logits = self.classifier(pooled_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Compute loss\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "        return {'loss': loss, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2\n",
    "gpt2 = transformers.GPT2Model.from_pretrained('gpt2', device_map='auto', torch_dtype='auto')\n",
    "\n",
    "# Initialize the model\n",
    "num_labels = 2  # Binary classification\n",
    "model = GPT2ForClassification(gpt2, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments to train for only 1 epoch\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.from_numpy(logits), dim=-1).numpy()\n",
    "    accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c76ada50a04189b552534c8e414d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0763, 'grad_norm': 1.3162119388580322, 'learning_rate': 4.840255591054313e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1627, 'grad_norm': 14.422348976135254, 'learning_rate': 4.680511182108626e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0203, 'grad_norm': 2.5744476318359375, 'learning_rate': 4.520766773162939e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1102, 'grad_norm': 4.313470363616943, 'learning_rate': 4.361022364217253e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0078, 'grad_norm': 0.8346872925758362, 'learning_rate': 4.201277955271566e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0208, 'grad_norm': 3.7981419563293457, 'learning_rate': 4.041533546325879e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0202, 'grad_norm': 0.8315554857254028, 'learning_rate': 3.8817891373801916e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0181, 'grad_norm': 1.277801752090454, 'learning_rate': 3.722044728434505e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0055, 'grad_norm': 0.40111127495765686, 'learning_rate': 3.562300319488818e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0086, 'grad_norm': 0.8114984035491943, 'learning_rate': 3.402555910543131e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0078, 'grad_norm': 0.2893454432487488, 'learning_rate': 3.242811501597444e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0371, 'grad_norm': 0.9061383008956909, 'learning_rate': 3.083067092651757e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1062, 'grad_norm': 0.14171816408634186, 'learning_rate': 2.9233226837060707e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0503, 'grad_norm': 0.8106814026832581, 'learning_rate': 2.7635782747603834e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0749, 'grad_norm': 0.18442629277706146, 'learning_rate': 2.6038338658146967e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0239, 'grad_norm': 0.33821073174476624, 'learning_rate': 2.44408945686901e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0821, 'grad_norm': 2.000694990158081, 'learning_rate': 2.284345047923323e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0601, 'grad_norm': 0.16026952862739563, 'learning_rate': 2.124600638977636e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1421, 'grad_norm': 7.5003437995910645, 'learning_rate': 1.964856230031949e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0769, 'grad_norm': 0.13450047373771667, 'learning_rate': 1.805111821086262e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1206, 'grad_norm': 0.36801525950431824, 'learning_rate': 1.645367412140575e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0148, 'grad_norm': 0.7890475392341614, 'learning_rate': 1.485623003194888e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0644, 'grad_norm': 0.07156912982463837, 'learning_rate': 1.3258785942492014e-05, 'epoch': 0.73}\n",
      "{'loss': 0.012, 'grad_norm': 0.027692284435033798, 'learning_rate': 1.1661341853035145e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1079, 'grad_norm': 0.1145092248916626, 'learning_rate': 1.0063897763578276e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1389, 'grad_norm': 0.2033568173646927, 'learning_rate': 8.466453674121406e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0806, 'grad_norm': 5.574522972106934, 'learning_rate': 6.869009584664538e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0815, 'grad_norm': 15.26062297821045, 'learning_rate': 5.2715654952076674e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0942, 'grad_norm': 0.2891586124897003, 'learning_rate': 3.6741214057507987e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0463, 'grad_norm': 0.23728826642036438, 'learning_rate': 2.0766773162939296e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0396, 'grad_norm': 0.3585697114467621, 'learning_rate': 4.792332268370607e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d67e220c6a42fe8abbc4953cf3d752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1542995572090149, 'eval_accuracy': 0.9744, 'eval_runtime': 6.2, 'eval_samples_per_second': 201.614, 'eval_steps_per_second': 12.742, 'epoch': 1.0}\n",
      "{'train_runtime': 31.5851, 'train_samples_per_second': 158.302, 'train_steps_per_second': 9.91, 'train_loss': 0.061585894265113926, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=313, training_loss=0.061585894265113926, metrics={'train_runtime': 31.5851, 'train_samples_per_second': 158.302, 'train_steps_per_second': 9.91, 'total_flos': 0.0, 'train_loss': 0.061585894265113926, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ce3fa6611845a39dbccd4d7e174910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1542995572090149,\n",
       " 'eval_accuracy': 0.9744,\n",
       " 'eval_runtime': 6.1685,\n",
       " 'eval_samples_per_second': 202.643,\n",
       " 'eval_steps_per_second': 12.807,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
